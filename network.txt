+-------------------------------------------------------------+-------------+
|                            Layer                            | #Parameters |
+-------------------------------------------------------------+-------------+
|    transformer.encoder.layers.0.self_attn.in_proj_weight    |    196608   |
|     transformer.encoder.layers.0.self_attn.in_proj_bias     |     768     |
|    transformer.encoder.layers.0.self_attn.out_proj.weight   |    65536    |
|     transformer.encoder.layers.0.self_attn.out_proj.bias    |     256     |
|         transformer.encoder.layers.0.linear1.weight         |    65536    |
|          transformer.encoder.layers.0.linear1.bias          |     256     |
|         transformer.encoder.layers.0.linear2.weight         |    65536    |
|          transformer.encoder.layers.0.linear2.bias          |     256     |
|          transformer.encoder.layers.0.norm1.weight          |     256     |
|           transformer.encoder.layers.0.norm1.bias           |     256     |
|          transformer.encoder.layers.0.norm2.weight          |     256     |
|           transformer.encoder.layers.0.norm2.bias           |     256     |
|    transformer.encoder.layers.1.self_attn.in_proj_weight    |    196608   |
|     transformer.encoder.layers.1.self_attn.in_proj_bias     |     768     |
|    transformer.encoder.layers.1.self_attn.out_proj.weight   |    65536    |
|     transformer.encoder.layers.1.self_attn.out_proj.bias    |     256     |
|         transformer.encoder.layers.1.linear1.weight         |    65536    |
|          transformer.encoder.layers.1.linear1.bias          |     256     |
|         transformer.encoder.layers.1.linear2.weight         |    65536    |
|          transformer.encoder.layers.1.linear2.bias          |     256     |
|          transformer.encoder.layers.1.norm1.weight          |     256     |
|           transformer.encoder.layers.1.norm1.bias           |     256     |
|          transformer.encoder.layers.1.norm2.weight          |     256     |
|           transformer.encoder.layers.1.norm2.bias           |     256     |
|    transformer.encoder.layers.2.self_attn.in_proj_weight    |    196608   |
|     transformer.encoder.layers.2.self_attn.in_proj_bias     |     768     |
|    transformer.encoder.layers.2.self_attn.out_proj.weight   |    65536    |
|     transformer.encoder.layers.2.self_attn.out_proj.bias    |     256     |
|         transformer.encoder.layers.2.linear1.weight         |    65536    |
|          transformer.encoder.layers.2.linear1.bias          |     256     |
|         transformer.encoder.layers.2.linear2.weight         |    65536    |
|          transformer.encoder.layers.2.linear2.bias          |     256     |
|          transformer.encoder.layers.2.norm1.weight          |     256     |
|           transformer.encoder.layers.2.norm1.bias           |     256     |
|          transformer.encoder.layers.2.norm2.weight          |     256     |
|           transformer.encoder.layers.2.norm2.bias           |     256     |
|    transformer.encoder.layers.3.self_attn.in_proj_weight    |    196608   |
|     transformer.encoder.layers.3.self_attn.in_proj_bias     |     768     |
|    transformer.encoder.layers.3.self_attn.out_proj.weight   |    65536    |
|     transformer.encoder.layers.3.self_attn.out_proj.bias    |     256     |
|         transformer.encoder.layers.3.linear1.weight         |    65536    |
|          transformer.encoder.layers.3.linear1.bias          |     256     |
|         transformer.encoder.layers.3.linear2.weight         |    65536    |
|          transformer.encoder.layers.3.linear2.bias          |     256     |
|          transformer.encoder.layers.3.norm1.weight          |     256     |
|           transformer.encoder.layers.3.norm1.bias           |     256     |
|          transformer.encoder.layers.3.norm2.weight          |     256     |
|           transformer.encoder.layers.3.norm2.bias           |     256     |
|               transformer.encoder.norm.weight               |     256     |
|                transformer.encoder.norm.bias                |     256     |
|    transformer.decoder.layers.0.self_attn.in_proj_weight    |    196608   |
|     transformer.decoder.layers.0.self_attn.in_proj_bias     |     768     |
|    transformer.decoder.layers.0.self_attn.out_proj.weight   |    65536    |
|     transformer.decoder.layers.0.self_attn.out_proj.bias    |     256     |
|  transformer.decoder.layers.0.multihead_attn.in_proj_weight |    196608   |
|   transformer.decoder.layers.0.multihead_attn.in_proj_bias  |     768     |
| transformer.decoder.layers.0.multihead_attn.out_proj.weight |    65536    |
|  transformer.decoder.layers.0.multihead_attn.out_proj.bias  |     256     |
|         transformer.decoder.layers.0.linear1.weight         |    65536    |
|          transformer.decoder.layers.0.linear1.bias          |     256     |
|         transformer.decoder.layers.0.linear2.weight         |    65536    |
|          transformer.decoder.layers.0.linear2.bias          |     256     |
|          transformer.decoder.layers.0.norm1.weight          |     256     |
|           transformer.decoder.layers.0.norm1.bias           |     256     |
|          transformer.decoder.layers.0.norm2.weight          |     256     |
|           transformer.decoder.layers.0.norm2.bias           |     256     |
|          transformer.decoder.layers.0.norm3.weight          |     256     |
|           transformer.decoder.layers.0.norm3.bias           |     256     |
|    transformer.decoder.layers.1.self_attn.in_proj_weight    |    196608   |
|     transformer.decoder.layers.1.self_attn.in_proj_bias     |     768     |
|    transformer.decoder.layers.1.self_attn.out_proj.weight   |    65536    |
|     transformer.decoder.layers.1.self_attn.out_proj.bias    |     256     |
|  transformer.decoder.layers.1.multihead_attn.in_proj_weight |    196608   |
|   transformer.decoder.layers.1.multihead_attn.in_proj_bias  |     768     |
| transformer.decoder.layers.1.multihead_attn.out_proj.weight |    65536    |
|  transformer.decoder.layers.1.multihead_attn.out_proj.bias  |     256     |
|         transformer.decoder.layers.1.linear1.weight         |    65536    |
|          transformer.decoder.layers.1.linear1.bias          |     256     |
|         transformer.decoder.layers.1.linear2.weight         |    65536    |
|          transformer.decoder.layers.1.linear2.bias          |     256     |
|          transformer.decoder.layers.1.norm1.weight          |     256     |
|           transformer.decoder.layers.1.norm1.bias           |     256     |
|          transformer.decoder.layers.1.norm2.weight          |     256     |
|           transformer.decoder.layers.1.norm2.bias           |     256     |
|          transformer.decoder.layers.1.norm3.weight          |     256     |
|           transformer.decoder.layers.1.norm3.bias           |     256     |
|    transformer.decoder.layers.2.self_attn.in_proj_weight    |    196608   |
|     transformer.decoder.layers.2.self_attn.in_proj_bias     |     768     |
|    transformer.decoder.layers.2.self_attn.out_proj.weight   |    65536    |
|     transformer.decoder.layers.2.self_attn.out_proj.bias    |     256     |
|  transformer.decoder.layers.2.multihead_attn.in_proj_weight |    196608   |
|   transformer.decoder.layers.2.multihead_attn.in_proj_bias  |     768     |
| transformer.decoder.layers.2.multihead_attn.out_proj.weight |    65536    |
|  transformer.decoder.layers.2.multihead_attn.out_proj.bias  |     256     |
|         transformer.decoder.layers.2.linear1.weight         |    65536    |
|          transformer.decoder.layers.2.linear1.bias          |     256     |
|         transformer.decoder.layers.2.linear2.weight         |    65536    |
|          transformer.decoder.layers.2.linear2.bias          |     256     |
|          transformer.decoder.layers.2.norm1.weight          |     256     |
|           transformer.decoder.layers.2.norm1.bias           |     256     |
|          transformer.decoder.layers.2.norm2.weight          |     256     |
|           transformer.decoder.layers.2.norm2.bias           |     256     |
|          transformer.decoder.layers.2.norm3.weight          |     256     |
|           transformer.decoder.layers.2.norm3.bias           |     256     |
|    transformer.decoder.layers.3.self_attn.in_proj_weight    |    196608   |
|     transformer.decoder.layers.3.self_attn.in_proj_bias     |     768     |
|    transformer.decoder.layers.3.self_attn.out_proj.weight   |    65536    |
|     transformer.decoder.layers.3.self_attn.out_proj.bias    |     256     |
|  transformer.decoder.layers.3.multihead_attn.in_proj_weight |    196608   |
|   transformer.decoder.layers.3.multihead_attn.in_proj_bias  |     768     |
| transformer.decoder.layers.3.multihead_attn.out_proj.weight |    65536    |
|  transformer.decoder.layers.3.multihead_attn.out_proj.bias  |     256     |
|         transformer.decoder.layers.3.linear1.weight         |    65536    |
|          transformer.decoder.layers.3.linear1.bias          |     256     |
|         transformer.decoder.layers.3.linear2.weight         |    65536    |
|          transformer.decoder.layers.3.linear2.bias          |     256     |
|          transformer.decoder.layers.3.norm1.weight          |     256     |
|           transformer.decoder.layers.3.norm1.bias           |     256     |
|          transformer.decoder.layers.3.norm2.weight          |     256     |
|           transformer.decoder.layers.3.norm2.bias           |     256     |
|          transformer.decoder.layers.3.norm3.weight          |     256     |
|           transformer.decoder.layers.3.norm3.bias           |     256     |
|               transformer.decoder.norm.weight               |     256     |
|                transformer.decoder.norm.bias                |     256     |
|                       generator.weight                      |     9216    |
|                        generator.bias                       |      36     |
|                 src_tok_emb.embedding.weight                |     9216    |
|                 tgt_tok_emb.embedding.weight                |     9216    |
+-------------------------------------------------------------+-------------+
Total Trainable Params: 4249636